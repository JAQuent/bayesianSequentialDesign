---
title: "Call on Sequential Bayesian Designs"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(plyr)
library(BayesFactor)
library(knitr)
library(assortedRFunctions)

options(scipen = 10)
```

This post is based on a short talk that I gave at the MRC CBU on the 29 July 2020 for a session on statistical power. The slides of presentation can be found in my [GitHub repository](https://github.com/JAQuent/bayesianSequentialDesign). This repository also includes the data and the scripts that were used to run the simulations and to create the figures. Most of this talk as well as of this post is based on Schoenbrodt & Wagenmakers' (2018) fantastic paper that I encourage you to read as well as the other good articles in that [special issue on Bayesian statistics](https://link.springer.com/journal/13423/25/1). 

So let's see what number we need for having a high probability of getting strong evidence for a medium effect (d = 0.5) and a null effect (d = 0.0). This cane be done in the same way a traditional power analysis using frequentist statistics is run. That is we can calculate for which fixed sample size we get a Bayes factor (BF) surpassing a certain criterion in let's say 80 % of the cases if repeated the data collection multiple times. 

This procedure is illustrated in the figure below, which basically the same as a standard power caluclation:

![Figure 1](figures/traditional.png) 

```{r, eval = TRUE}
load("simulationResults.RData")

crit1 <- 10
crit2 <- 1/6

# Calculatge percentage
df1_2            <- subset(df1, df1$side == 2)
df1_2$overCrit1  <- df1_2$bf > crit1
df1_2$belowCrit2 <- df1_2$bf < crit2
df1_2[df1_2$d == 0.0, 'overCrit1']  <- NA
df1_2[df1_2$d == 0.5, 'belowCrit2'] <- NA
df1_2_agg         <- ddply(df1_2, c('n'), summarise, per_crit1 = mean(overCrit1, na.rm = TRUE), per_crit2 = mean(belowCrit2, na.rm = TRUE))

# Misleading evidence
df1_2_miss            <- df1_2
df1_2_miss$overCrit1  <- df1_2_miss$bf > crit1
df1_2_miss$belowCrit2 <- df1_2_miss$bf < crit2
df1_2_miss_agg        <- ddply(df1_2_miss, c('n', 'd'), summarise, per_crit1 = mean(overCrit1, na.rm = TRUE), per_crit2 = mean(belowCrit2, na.rm = TRUE))



table1 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(min(df1_2_agg[df1_2_agg$per_crit1 >= 0.8, 'n']), min(df1_2_agg[df1_2_agg$per_crit2 >= 0.8, 'n'])),
                     v3 = c(df1_2_miss_agg[df1_2_miss_agg$n == min(df1_2_agg[df1_2_agg$per_crit1 >= 0.8, 'n']) & df1_2_miss_agg$d == 0.5 , 'per_crit2'], 
                            df1_2_miss_agg[df1_2_miss_agg$n == min(df1_2_agg[df1_2_agg$per_crit2 >= 0.8, 'n']) & df1_2_miss_agg$d == 0.0 , 'per_crit1']))

names(table1) <- c('Effect size', 'Necessary sample size', 'Misleading evidence in %')
                     
table1$`£ for online experiment` <- round(table1$`Necessary sample size`*8.40)
table1$`£ for fMRI experiment`   <- round(table1$`Necessary sample size`*550)
```

Above you can see the results of a traditional fixed sample size design analysis. This analysis is based on a Bayesian one-sample _t_-test and shows the percentage of surpassing the criteria as a function of the sample size. The blue line shows the percentage for $BF_{10}$ over 10 for a true medium effect size, while the red line shows a $BF_{10}$ below 1/6 for a true null effect size. I chose this asymmetric cut-off because it is much more difficult to get strong evidence for the point $H_0$ than it is for the $H_1$. Actually, to reach high percentage values like 95 % (as some journals require), we would need a sample size that is much larger than this. By the way, this simulation like on the all in this post was based on 10,000 iterations. If we plan for true effect size of 0.5, the necessary sample size is `r table1[1,2]`, while it is `r table1[2,2]` if the true effect size is 0.0. Collecting a sample size that is that large for one experiment is quite impossible for a basic science experiment in my field (cognitive neuroscience) if it is not run online. Also remember that this is a one-sample _t_-test with two inpendent samples the necessary sample size would be even larger. 

The good thing though is that there is a way to reliably produce strong evidence with samples that are (on average) much smaller: _Sequential Bayesian Designs_. In a sequential design we essentially keep on collecting data until reach the one of the pre-specified evidence criteria for instance a $BF_{10} > 10$ or $BF_{10} < 1/6$. Below you see an piece of code that can run this kind of simulation in simple a loop.

```{r, eval = FALSE, echo = TRUE}
# Setting seed
set.seed(2)

# Parameters
minN      <- 10   # Staring sample size
batchSize <- 5    # How often is the BF checked
crit1     <- 10   # Upper criterion: evidence for H1
crit2     <- 1/6  # Lower criterion: evidence for H0 
nIter     <- 100  # Number of iterations for simulation 
d         <- 0    # Effect size

for(i in 1:nIter){
  # First iteration
  data <- rnorm(minN, d, 1)
  n    <- minN
  bf   <- reportBF(ttestBF(data))
  
  # Loop
  while(bf[length(bf)] < crit1 & bf[length(bf)] > crit2){
    data <- c(data, rnorm(minN, d, 1))
    bf[length(bf) + 1] <- reportBF(ttestBF(data))
    n[length(n) + 1]   <- n[length(n)] + batchSize
  }
  
  if(i == 1){
    df <- data.frame(id = rep(i, length(bf)), n = n, bf = bf)
  } else {
    df <- rbind(df, data.frame(id =  rep(i, length(bf)), n = n, bf = bf))
  }
}
```

The code above was used to create the simulation shown bloew. In this example we start with a sample size of 10 and then keep adding 5 more data points until we either reach `crit1` or `crit2`. The true effect size here is 0.0.On the x-axis you find the sample size and on the y-axis you find $BF_{1o$}. Each individual line represents one run in this simulation. 

![](figures/anim.gif)


A full simulation of 10,000 iteration is shown in the figure below. The true effect size here is 0.0.

```{r, eval = TRUE, echo = FALSE}
nIter <- 10000

############### d = 0.0
tempDF <- subset(df2, side == 2 & d == 0.0)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'

# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))

# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))

# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                            c('n', 'band'),
                            summarise,
                            freq = length(bf)/nIter)
# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                            c('n', 'band'),
                            summarise,
                            freq = length(bf)/nIter)

# Get sample sizes
sampleSize_df1           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df1$count     <- sampleSize_df1$freq * nIter
tempDF_agg_supp_H1$count <- tempDF_agg_supp_H1$freq * nIter

#Calculate results
avgN1    <- round(mean(rep(sampleSize_df1$n, sampleSize_df1$count)))
misLead1 <- sum(tempDF_agg_supp_H1$freq)*100
maxN1    <- max(tempDF_agg$n)
```

![](figures/pure1.png)

Here is a quick explanation of that this figure shows. Like in the animation, each individual line in the middle part of the figure represents one iteration of this simulation. The lines are colour coded based on the final BF (red = $BF_{10} > 10$, purple =  $BF_{10} < 1/6$). At the top and the bottom, you see histograms showing how many BF were above and below the criteria for each sample size. Two things are apparent at the first glance. First, there is very little misleading evidence. Misleading evidence for this simulation means $BF_{10} > 10$. The red lines in the middle and the barely perceptible red bars in the top histogram visualise this. Second, most simulations end well before the `r table1[2, 2]` that are need to get a $BF_{10} < 1/6$ in 80 % of the times as in the traditional design but we also see that in some cases data collection goes well beyond 500 data points. In fact this figure is capped at 1000 for illustration. The highest sample size was actually `r maxN1` and `r sum(tempDF_agg$n > 1000)` were above 1000. However over average, we can stop data collection with sample size of only `r avgN1`, which is much lower than the need in the traditional approach. For further illustration, I also present a simulation were we have true medium effect size. 

![](figures/pure2.png)


```{r, echo = FALSE, eval = TRUE}
############### d = 0.5
tempDF <- subset(df2, side == 2 & d == 0.5)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'


# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)

# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)


sampleSize_df2           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df2$count     <- sampleSize_df2$freq * nIter
tempDF_agg_supp_H0$count <- tempDF_agg_supp_H0$freq * nIter

# Calculate results
avgN2    <- round(mean(rep(sampleSize_df2$n, sampleSize_df2$count)))
misLead2 <- sum(tempDF_agg_supp_H0$freq)*100
maxN2    <- max(tempDF_agg$n)
```

This figure also clearly shows that most runs end much earlier than the `r table1[1, 2]` from the fixed sample size design. The highest sample size for this effect size is `r maxN2`. 

Now, to the most interesting part that is comparing the traditional fixed sample size design and the sequential design directly. In the table below, you see the costs for an 1-hour long online experiment on prolific (£ 8.4) and an 1-hour long fMRI experiment (full economic costs of £ 550). 

```{r, echo = FALSE}
kable(table1)
```

Based on the results, we would need to spend a lot of money for each experiment. In the worst case scenario, where you plan to provide evidence for a null effect in fMRI experiment, you would have to spend £ `r table1[2, 5]` it's less if you plan for a medium effect size but the problem is often we don't really have good estimate of the effect size. If we did, we might not even run the experiment. Johan Carlin recently gave a talk where he among other things discussed the problem of biased effect size estimates that lead to low power. His talk can be found [here](https://twitter.com/johancarlin/status/1273186119564144641).


```{r, eval = TRUE, echo = FALSE}
table2_2 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(avgN2, avgN1),
                     v3 = c(maxN2, maxN1),
                     v3 = c(misLead2, misLead1))

names(table2_2) <- c('Effect size', 'Average sample size', 'Maximal sample size', 'Misleading evidence in %')

table2_2$`£ for online experiment` <- round(table2_2$`Average sample size`*8.40)
table2_2$`£ for fMRI experiment`   <- round(table2_2$`Average sample size`*550)
kable(table2_2)
```


With a true sequential design we don't have this problem at all. Regardless of the true effect size we produce strong evidence and this on average much cheaper than with a fixed sample design. The average cost for an fMRI experiment for instance is only £ `r  table2_2[2, 6]`. This is only `r round(table2_2[2, 6]/table1[2, 5], 2)*100` % of the cost that we'd have to play for a traditional design. At the same time, it needs to be acknowledged that the misleading evidence rates in much higher in sequential designs are much higher but still very low. For instance, for null effect in this simulation it is `r table2_2[2, 4]` %. If misleading evidence rates are of concerns then one thing that can be done is to increase the minimal sample size and the number of data points added in each batch. The effect of doing this is illustrated further below. 

A much bigger problem is that while the average sample size is much lower, sometimes we're unlucky and we haven't reached a stopping criterion even after 1000 data points. For a PhD student running an fMRI experiment, this is just not feasible. Despite what [2 Unlimited](https://www.youtube.com/watch?v=awEnGXcmUXc) wants us to believe, practically there is often a limit that can be based on money, available participants or time constraints. One way to protect oneself against collecting extremely large samples is to set an upper limit and to accept that in rare and extreme cases we might stop despite note having reached a criterion and ending with inconclusive evidence. Something that can also happen in a fixed sample size design. In the following, I will present simulations where data collection is stopped after collecting 100 data points regardless of whether an evidence criterion is reached. The additional histogram on the right side illustrates the distribution of $BF_{10}$ when stopped at 100.  

![](figures/limit1.png)

![](figures/limit2.png)

```{r, eval = TRUE}
# Parmeter
maxN <- 100

###### D = 0.0
tempDF <- subset(df3, d == 0.0)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'

# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)

# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n == maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}


sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H1$count <- tempDF_agg_supp_H1$freq * nIter

# Get summary
avgN1       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead1    <- sum(tempDF_agg_supp_H1$freq)*100
strongEvi1  <- sum(tempDF_agg_supp_H0$freq)*100
undecided1  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100


######## d = 0.5
tempDF <- subset(df3, d == 0.5)
tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'


# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)





# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n == maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}



sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H0$count <- tempDF_agg_supp_H0$freq * nIter

# Get summary
avgN2       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead2    <- sum(tempDF_agg_supp_H0$freq)*100
strongEvi2  <- sum(tempDF_agg_supp_H1$freq)*100
undecided2  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100
```


```{r, eval = TRUE}
table3 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(avgN2, avgN1),
                     v3 = c(strongEvi2, strongEvi1),
                     v4 = c(misLead2, misLead1),
                     v5 = c(undecided2, undecided1))

names(table3) <- c('Effect size', 'Average sample size', 'Strong evidence in %', 'Misleading evidence in %', 'Insufficient evidence in %')
kable(table3)
```

Stopping at 100 data points protects against having to collect extremely large samples but this approach still produces solid evidence in most cases even is the true effect is zero.

# Take home message

It is important to find the right parameters for the specific situation that will lead to the most efficient data collection. Several factors influence the performance of Bayesian Sequential Designs. Those are 

- minimum sample size influences the rate of misleading evidence,
- batch size (i.e. after how many new data points we check evidence),
- choice priors and likelihood functions (If you want evidence for $H_0$, there are better choices for this type of data. See my previous __[post](https://jaquent.github.io/post/comparing-different-methods-to-calculate-bayes-factors-for-a-simple-model/)__ on this issue) and
- directed vs. undirected hypothesis.

To get some idea how the parameters affect the performance of the sequential designs I've compiled a summary table of a couple of simulation that I ran for this talk. All simulations have the same effect sizes and the same number of iterations (10,000). 


```{r}
# Calculatge percentage
df1_1            <- subset(df1, df1$side == 1)
df1_1$overCrit1  <- df1_1$bf > crit1
df1_1$belowCrit2 <- df1_1$bf < crit2
df1_1[df1_1$d == 0.0, 'overCrit1']  <- NA
df1_1[df1_1$d == 0.5, 'belowCrit2'] <- NA
df1_1_agg         <- ddply(df1_1, c('n'), summarise, per_crit1 = mean(overCrit1, na.rm = TRUE), per_crit2 = mean(belowCrit2, na.rm = TRUE))

# Misleading evidence
df1_1_miss            <- df1_1
df1_1_miss$overCrit1  <- df1_1_miss$bf > crit1
df1_1_miss$belowCrit2 <- df1_1_miss$bf < crit2
df1_1_miss_agg        <- ddply(df1_1_miss, c('n', 'd'), summarise, per_crit1 = mean(overCrit1, na.rm = TRUE), per_crit2 = mean(belowCrit2, na.rm = TRUE))

table1_1 <- data.frame(v1 = c(0.5, 0.0),
                       v2 = c(min(df1_1_agg[df1_1_agg$per_crit1 >= 0.8, 'n']), min(df1_1_agg[df1_1_agg$per_crit2 >= 0.8, 'n'])),
                       v3 = c(df1_1_miss_agg[df1_1_miss_agg$n == min(df1_1_agg[df1_1_agg$per_crit1 >= 0.8, 'n']) & df1_1_miss_agg$d == 0.5 , 'per_crit2'], 
                            df1_1_miss_agg[df1_1_miss_agg$n == min(df1_1_agg[df1_1_agg$per_crit2 >= 0.8, 'n']) & df1_1_miss_agg$d == 0.0 , 'per_crit1']))

names(table1_1) <- c('Effect size', 'Necessary sample size', 'Misleading evidence in %')
                     
table1_1$`£ for online experiment` <- round(table1_1$`Necessary sample size`*8.40)
table1_1$`£ for fMRI experiment`   <- round(table1_1$`Necessary sample size`*550)
```

```{r}
nIter <- 10000

############### d = 0.0
tempDF <- subset(df2, side == 1 & d == 0.0)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'

# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))

# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))

# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                            c('n', 'band'),
                            summarise,
                            freq = length(bf)/nIter)
# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                            c('n', 'band'),
                            summarise,
                            freq = length(bf)/nIter)

# Get sample sizes
sampleSize_df1           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df1$count     <- sampleSize_df1$freq * nIter
tempDF_agg_supp_H1$count <- tempDF_agg_supp_H1$freq * nIter

#Calculate results
avgN1    <- round(mean(rep(sampleSize_df1$n, sampleSize_df1$count)))
misLead1 <- sum(tempDF_agg_supp_H1$freq)*100
maxN1    <- max(tempDF_agg$n)

############### d = 0.5
tempDF <- subset(df2, side == 1 & d == 0.5)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'


# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)

# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)


sampleSize_df2           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df2$count     <- sampleSize_df2$freq * nIter
tempDF_agg_supp_H0$count <- tempDF_agg_supp_H0$freq * nIter

# Calculate results
avgN2    <- round(mean(rep(sampleSize_df2$n, sampleSize_df2$count)))
misLead2 <- sum(tempDF_agg_supp_H0$freq)*100
maxN2    <- max(tempDF_agg$n)

# Create table
table2_1 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(avgN2, avgN1),
                     v3 = c(maxN2, maxN1),
                     v3 = c(misLead2, misLead1))

names(table2_1) <- c('Effect size', 'Average sample size', 'Maximal sample size', 'Misleading evidence in %')

table2_1$`£ for online experiment` <- round(table2_1$`Average sample size`*8.40)
table2_1$`£ for fMRI experiment`   <- round(table2_1$`Average sample size`*550)
```

```{r}
# Parmeter
maxN <- 100

###### D = 0.0
tempDF <- subset(df4, d == 0.0)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'

# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)

# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n == maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}


sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H1$count <- tempDF_agg_supp_H1$freq * nIter

# Get summary
avgN1       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead1    <- sum(tempDF_agg_supp_H1$freq)*100
strongEvi1  <- sum(tempDF_agg_supp_H0$freq)*100
undecided1  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100


######## d = 0.5
tempDF <- subset(df4, d == 0.5)
tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'


# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)





# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n == maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}



sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H0$count <- tempDF_agg_supp_H0$freq * nIter

# Get summary
avgN2       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead2    <- sum(tempDF_agg_supp_H0$freq)*100
strongEvi2  <- sum(tempDF_agg_supp_H1$freq)*100
undecided2  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100
```


```{r, eval = TRUE}
table4 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(avgN2, avgN1),
                     v3 = c(strongEvi2, strongEvi1),
                     v4 = c(misLead2, misLead1),
                     v5 = c(undecided2, undecided1))

names(table4) <- c('Effect size', 'Average sample size', 'Strong evidence in %', 'Misleading evidence in %', 'Insufficient evidence in %')
```


```{r}
# Parmeter
maxN <- 100

###### D = 0.0
tempDF <- subset(df5, d == 0.0)

tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'

# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)

# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n >= maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}


sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H1$count <- tempDF_agg_supp_H1$freq * nIter

# Get summary
avgN1       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead1    <- sum(tempDF_agg_supp_H1$freq)*100
strongEvi1  <- sum(tempDF_agg_supp_H0$freq)*100
undecided1  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100


######## d = 0.5
tempDF <- subset(df5, d == 0.5)
tempDF$trans_bf <- NA
tempDF$trans_bf[tempDF$bf < 1] <- -1/tempDF$bf[tempDF$bf < 1] + 1
tempDF$trans_bf[tempDF$bf > 1] <- tempDF$bf[tempDF$bf > 1] - 1

tempDF_agg <- ddply(tempDF, c('id'), summarise, n = n[length(n)], bf = bf[length(bf)])
tempDF_agg$support <- 'undecided'
tempDF_agg$support[tempDF_agg$bf > crit1] <- 'H1'
tempDF_agg$support[tempDF_agg$bf < crit2] <- 'H0'


# Creates band
tempDF_agg$band                                             <- '> 10'
tempDF_agg$band[tempDF_agg$bf < 10 & tempDF_agg$bf > 6]     <- '> 6'
tempDF_agg$band[tempDF_agg$bf < 6 & tempDF_agg$bf > 3]      <- '> 3'
tempDF_agg$band[tempDF_agg$bf < 3 & tempDF_agg$bf > 1]      <- '> 1'
tempDF_agg$band[tempDF_agg$bf < 1 & tempDF_agg$bf > 1/3]    <- '< 1'
tempDF_agg$band[tempDF_agg$bf < 1/3 & tempDF_agg$bf > 1/6]  <- '< 1/3'
tempDF_agg$band[tempDF_agg$bf < 1/6 & tempDF_agg$bf > 1/10] <- '< 1/6'
tempDF_agg$band[tempDF_agg$bf < 1/10]                       <- '< 1/10'

# Create factor band
tempDF_agg$band <- factor(tempDF_agg$band, levels = c('> 10', '> 6', '> 3', '> 1', '< 1', '< 1/3', '< 1/6', '< 1/10'))


# Get back to main DF
tempDF$band <- rep(tempDF_agg$band, table(tempDF$id))


# Create upper histogram
tempDF_agg_supp_H1 <- ddply(subset(tempDF_agg, support == 'H1'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)





# Create right histogram
tempDF_agg_undecided <- subset(tempDF_agg, tempDF_agg$n >= maxN & tempDF_agg$bf < crit1 & tempDF_agg$bf > crit2)
tempDF_agg_undecided$trans_bf <- NA
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf < 1] <- -1/tempDF_agg_undecided$bf[tempDF_agg_undecided$bf < 1] + 1
tempDF_agg_undecided$trans_bf[tempDF_agg_undecided$bf > 1] <- tempDF_agg_undecided$bf[tempDF_agg_undecided$bf > 1] - 1


# Create lower histogram
tempDF_agg_supp_H0 <- ddply(subset(tempDF_agg, support == 'H0'),
                           c('n', 'band'),
                           summarise,
                           freq = length(bf)/nIter)



# Creates empty df for plotting if no values
if(nrow(tempDF_agg_supp_H0) == 0){
  tempDF_agg_supp_H0 <- data.frame(n = seq(1, 5, 1),
                                band = rep('< 1/10', 5),
                                freq = rep(0, 5))
}



sampleSize_df3           <- rbind(tempDF_agg_supp_H0, tempDF_agg_supp_H1)
sampleSize_df3$count     <- sampleSize_df3$freq * nIter
tempDF_agg_supp_H0$count <- tempDF_agg_supp_H0$freq * nIter

# Get summary
avgN2       <- round(mean(rep(sampleSize_df3$n, sampleSize_df3$count)))
misLead2    <- sum(tempDF_agg_supp_H0$freq)*100
strongEvi2  <- sum(tempDF_agg_supp_H1$freq)*100
undecided2  <- round(nrow(tempDF_agg_undecided)/nIter, 4)*100
```


```{r, eval = TRUE}
table5 <- data.frame(v1 = c(0.5, 0.0),
                     v2 = c(avgN2, avgN1),
                     v3 = c(strongEvi2, strongEvi1),
                     v4 = c(misLead2, misLead1),
                     v5 = c(undecided2, undecided1))

names(table5) <- c('Effect size', 'Average sample size', 'Strong evidence in %', 'Misleading evidence in %', 'Insufficient evidence in %')
```


```{r}

table6 <- data.frame(v1  = c('Fixed n', 'Fixed n', 'Fixed n', 'Fixed n', 'Sequential', 'Sequential', 'Sequential', 'Sequential'),
                     v2  = c('2-sided', '2-sided', '1-sided', '1-sided', '2-sided', '2-sided', '1-sided', '1-sided'),
                     v3  = c(NA, NA, NA, NA, 10, 10, 10, 10),
                     v4  = c(NA, NA, NA, NA, 5, 5, 5, 5),
                     v5  = c(NA, NA, NA, NA, NA, NA, NA, NA), 
                     v6  = c(0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0),
                     v7  = c(0.8, 0.8, 0.8, 0.8, 1, 1, 1, 1),
                     v8  = c(table1[1, 2], table1[2, 2], table1_1[1, 2], table1_1[2, 2], table2_2[1, 2], table2_2[2, 2], table2_1[1, 2], table2_1[2, 2]),
                     v9  = c(table1[1, 3], table1[2, 3], table1_1[1, 3], table1_1[2, 3], table2_2[1, 4], table2_2[2, 4], table2_1[1, 4], table2_1[2, 4]),
                     v10 = c(table1[1, 4], table1[2, 4], table1_1[1, 4], table1_1[2, 4], table2_2[1, 5], table2_2[2, 5], table2_1[1, 5], table2_1[2, 5]),
                     v11 = c(table1[1, 5], table1[2, 5], table1_1[1, 5], table1_1[2, 5], table2_2[1, 6], table2_2[2, 6], table2_1[1, 6], table2_1[2, 6]))

# Also make percentage
table6$v7 <- table6$v7*100

table6 <- rbind(table6, data.frame(v1  = c('Sequential', 'Sequential', 'Sequential', 'Sequential', 'Sequential', 'Sequential'),
                     v2  = c('2-sided', '2-sided'),
                     v3  = c(10, 10, 10, 10, 2, 2),
                     v4  = c(5, 5, 1, 1, 5, 5),
                     v5  = c(100, 100, 100, 100, 100, 100), 
                     v6  = c(0.5, 0.0, 0.5, 0.0, 0.5, 0.0),
                     v7  = c(table3[1, 3], table3[2, 3], table4[1, 3], table4[2, 3], table5[1, 3], table5[2, 3]),
                     v8  = c(table3[1, 2], table3[2, 2], table4[1, 2], table4[2, 2], table5[1, 2], table5[2, 2]),
                     v9  = c(table3[1, 4], table3[2, 4], table4[1, 4], table4[2, 4], table5[1, 4], table5[2, 4]),
                     v10 = c(round(table3[1, 2]*8.40), round(table3[2, 3]*8.40), round(table4[1, 2]*8.40), round(table4[2, 3]*8.40), 
                             round(table5[1, 2]*8.40), round(table5[2, 3]*8.40)),
                     v11 = c(round(table3[1, 2]*550), round(table3[2, 3]*550), round(table4[1, 2]*550), round(table4[2, 3]*550),
                             round(table5[1, 2]*550), round(table5[2, 3]*550))))

names(table6) <- c('Design', 'Direction', 'Minimal N', 'Batch size', 'Maximal N', 'Effect size', 'BF > crit %', 'Sample size', 'Misleading evidence %', '£ online experiment', '£ fMRI experiment')

kable(table6)
```

Surprising sequential designs seem to be actually realtively robust. Note that the estimation of the misleading evidence rates also seems to be a bit noisy (despite running 10,000 iterations). For the scope of my talk I haven't ran more simulations but it can be expected to find clearer results eith more extreme cases are compared. 

All in all, I hope that I could show that sequential designs perform well regardless of the sampling plan and are in most cases to fixed sample size designs. I think as insitutions and individuals dealing with money from tax payers we should try to work efficiently. Therefore, we should collect only as much data as we need. Obviously this is even more important if our work (potentially) causes harm as in animal experiments or work with patients. 

# References
Schönbrodt, F. D., & Wagenmakers, E.-J. (2018). _Bayes factor design analysis: Planning for compelling evidence_. Psychonomic Bulletin & Review, 25(1), 128–142. https://doi.org/10.3758/s13423-017-1230-y

# Code
The data and the source code can be found [here](https://github.com/JAQuent/bayesianSequentialDesign).
The .Rmd file used to generated the code can be found [here](https://github.com/JAQuent/bayesianSequentialDesign/blob/master/backgroundScript.Rmd).